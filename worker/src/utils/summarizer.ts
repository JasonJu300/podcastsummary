import type { Env } from '../types';

// ç«å±±æ–¹èˆŸ LLM API
const DEFAULT_MODEL = 'ep-20260116190645-55rqn'; // Doubao model

// Max characters per segment (approx 6k tokens)
const MAX_SEGMENT_CHARS = 12000;

export async function summarizeTranscript(transcript: string, env: Env): Promise<string | null> {
  try {
    // For long transcripts, split and summarize in segments
    if (transcript.length > MAX_SEGMENT_CHARS) {
      return await summarizeLongTranscript(transcript, env);
    }

    return await callLLM(transcript, getMainPrompt(), env);
  } catch (error) {
    console.error('Summarization error:', error);
    return null;
  }
}

async function summarizeLongTranscript(transcript: string, env: Env): Promise<string | null> {
  // Split into segments
  const segments = splitIntoSegments(transcript, MAX_SEGMENT_CHARS);
  const segmentSummaries: string[] = [];

  for (let i = 0; i < segments.length; i++) {
    const prompt = `è¿™æ˜¯ä¸€æ®µæ’­å®¢è½¬å½•æ–‡æœ¬çš„ç¬¬ ${i + 1}/${segments.length} éƒ¨åˆ†ã€‚è¯·æå–è¿™éƒ¨åˆ†çš„å…³é”®å†…å®¹å’Œè¦ç‚¹ï¼š\n\n${segments[i]}`;
    const summary = await callLLM(prompt, 'ä½ æ˜¯ä¸€ä¸ªæ’­å®¢å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œè¯·æå–è¾“å…¥æ–‡æœ¬çš„å…³é”®ä¿¡æ¯å’Œè¦ç‚¹ã€‚', env);
    if (summary) {
      segmentSummaries.push(summary);
    }
  }

  if (segmentSummaries.length === 0) return null;

  // Merge segment summaries into final summary
  const combined = segmentSummaries.join('\n\n---\n\n');
  const mergePrompt = `ä»¥ä¸‹æ˜¯ä¸€ä¸ªæ’­å®¢å„æ®µè½çš„è¦ç‚¹æ‘˜è¦ï¼Œè¯·å°†å®ƒä»¬æ•´åˆä¸ºä¸€ç¯‡å®Œæ•´çš„ç»“æ„åŒ–æ‘˜è¦æ–‡ç« ï¼š\n\n${combined}`;
  return await callLLM(mergePrompt, getMainPrompt(), env);
}

function splitIntoSegments(text: string, maxChars: number): string[] {
  const segments: string[] = [];
  const lines = text.split('\n');
  let current = '';

  for (const line of lines) {
    if (current.length + line.length + 1 > maxChars && current.length > 0) {
      segments.push(current);
      current = line;
    } else {
      current += (current ? '\n' : '') + line;
    }
  }

  if (current) segments.push(current);
  return segments;
}

function getMainPrompt(): string {
  return 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ’­å®¢å†…å®¹åˆ†æå¸ˆï¼Œæ“…é•¿æå–å…³é”®ä¿¡æ¯å¹¶ç”Ÿæˆç»“æ„åŒ–çš„æ‘˜è¦æ–‡ç« ã€‚è¯·ç”¨ Markdown æ ¼å¼è¾“å‡ºã€‚';
}

async function callLLM(content: string, systemPrompt: string, env: Env): Promise<string | null> {
  const prompt = content.includes('è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º') ? content : `è¯·å¯¹ä»¥ä¸‹æ’­å®¢å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œç”Ÿæˆä¸€ç¯‡ç»“æ„åŒ–çš„æ‘˜è¦æ–‡ç« ï¼š

${content}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ğŸ“Œ æ ¸å¿ƒè§‚ç‚¹
ï¼ˆåˆ—å‡º 3-5 ä¸ªæ ¸å¿ƒè§‚ç‚¹ï¼Œç”¨ç®€æ´æœ‰åŠ›çš„è¯­è¨€ï¼‰

## ğŸ“ å†…å®¹æ‘˜è¦
ï¼ˆè¯¦ç»†çš„æ®µè½æ‘˜è¦ï¼ŒåŒ…å«ä¸»è¦è®¨è®ºå†…å®¹å’Œè§è§£ï¼Œåˆ†å¤šä¸ªæ®µè½ï¼‰

## ğŸ’¡ å…³é”®è¦ç‚¹
ï¼ˆåˆ—å‡ºå…³é”®è¦ç‚¹å’Œå¯æ‰§è¡Œçš„å»ºè®®ï¼Œä½¿ç”¨æœ‰åºåˆ—è¡¨ï¼‰

## ğŸ¯ é€‚åˆäººç¾¤
ï¼ˆæè¿°è¿™ä¸ªæ’­å®¢é€‚åˆå“ªäº›å¬ä¼—ï¼‰

è¯·ç”¨ä¸­æ–‡è¾“å‡ºï¼Œä¿æŒä¸“ä¸šä½†æ˜“è¯»çš„å†™ä½œé£æ ¼ã€‚ä½¿ç”¨ Markdown æ ¼å¼ã€‚`;

  const response = await fetch(`${env.ARK_BASE_URL}/chat/completions`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${env.ARK_API_KEY}`,
    },
    body: JSON.stringify({
      model: DEFAULT_MODEL,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt },
      ],
      temperature: 0.7,
      max_tokens: 4000,
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    console.error('LLM API error:', response.status, error);
    return null;
  }

  const data = await response.json() as {
    choices?: Array<{ message?: { content?: string } }>;
  };
  return data.choices?.[0]?.message?.content || null;
}
